{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENIGMABOT Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENIGMABOT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ENIGMABOT, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(256, 32)\n",
    "        self.lstm = nn.LSTM(32,128, 2, batch_first=True, dropout=.1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(128, 256)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input)\n",
    "        output = self.lstm(embedded)[0][:,-1,:]\n",
    "        prediction = self.fc(output)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ENIGMABOT()\n",
    "model.load_state_dict(torch.load(\"enigmabot_model.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(text):\n",
    "    return torch.Tensor([[int(ord(x)) for x in text]]).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transmission = \"9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8Kj 2Sq7Ji\"\n",
    "flag = \": ingeneer{IMMUNEBOOSTERSREADY.PATHOGENMUTATIONSTABILIZED.DISTRIBUTIONPLAN}\"\n",
    "\n",
    "text = transmission + flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['sequence', 'target'])\n",
    "\n",
    "for i in range(0, len(flag)):\n",
    "    data.loc[i] = [text[:i + len(transmission)], text[i + len(transmission)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8...</td>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8...</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8...</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8...</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8...</td>\n",
       "      <td>}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sequence target\n",
       "0   9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8...      :\n",
       "1   9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8...       \n",
       "2   9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8...      i\n",
       "3   9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8...      n\n",
       "4   9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8...      g\n",
       "..                                                ...    ...\n",
       "70  9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8...      P\n",
       "71  9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8...      L\n",
       "72  9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8...      A\n",
       "73  9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8...      N\n",
       "74  9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8...      }\n",
       "\n",
       "[75 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 4.6901111284891766\n",
      "Epoch [2/100], Loss: 3.2945802942911784\n",
      "Epoch [3/100], Loss: 2.8725102583567304\n",
      "Epoch [4/100], Loss: 2.6518141214052835\n",
      "Epoch [5/100], Loss: 2.2307767923672994\n",
      "Epoch [6/100], Loss: 2.0916917792956036\n",
      "Epoch [7/100], Loss: 2.057218872706095\n",
      "Epoch [8/100], Loss: 1.4733907500902812\n",
      "Epoch [9/100], Loss: 1.1863986877600352\n",
      "Epoch [10/100], Loss: 0.860781389772892\n",
      "Epoch [11/100], Loss: 0.6491092353065808\n",
      "Epoch [12/100], Loss: 0.5153728369871775\n",
      "Epoch [13/100], Loss: 0.42967908799648286\n",
      "Epoch [14/100], Loss: 0.2983924443771442\n",
      "Epoch [15/100], Loss: 0.27641010517875353\n",
      "Epoch [16/100], Loss: 0.24774437223871548\n",
      "Epoch [17/100], Loss: 0.21848746811350186\n",
      "Epoch [18/100], Loss: 0.15501481983810664\n",
      "Epoch [19/100], Loss: 0.08811107128858567\n",
      "Epoch [20/100], Loss: 0.07343442837397257\n",
      "Epoch [21/100], Loss: 0.052741703366239866\n",
      "Epoch [22/100], Loss: 0.058771563284099104\n",
      "Epoch [23/100], Loss: 0.10963926969096065\n",
      "Epoch [24/100], Loss: 0.05716527589907249\n",
      "Epoch [25/100], Loss: 0.051254064086824654\n",
      "Epoch [26/100], Loss: 0.04785112364217639\n",
      "Epoch [27/100], Loss: 0.04814056855936845\n",
      "Epoch [28/100], Loss: 0.06711443154141307\n",
      "Epoch [29/100], Loss: 0.03690196537412703\n",
      "Epoch [30/100], Loss: 0.01966592004833122\n",
      "Epoch [31/100], Loss: 0.01363464410416782\n",
      "Epoch [32/100], Loss: 0.012119332713385424\n",
      "Epoch [33/100], Loss: 0.010203674469764034\n",
      "Epoch [34/100], Loss: 0.00950192318763584\n",
      "Epoch [35/100], Loss: 0.0083638213823239\n",
      "Epoch [36/100], Loss: 0.007902961436969539\n",
      "Epoch [37/100], Loss: 0.006835006858843068\n",
      "Epoch [38/100], Loss: 0.006507040651825567\n",
      "Epoch [39/100], Loss: 0.006161402358363072\n",
      "Epoch [40/100], Loss: 0.005332019389607012\n",
      "Epoch [41/100], Loss: 0.005048552639782429\n",
      "Epoch [42/100], Loss: 0.0048162672373776635\n",
      "Epoch [43/100], Loss: 0.004472417814346651\n",
      "Epoch [44/100], Loss: 0.004136368058001002\n",
      "Epoch [45/100], Loss: 0.003940417193807662\n",
      "Epoch [46/100], Loss: 0.0035363824153319\n",
      "Epoch [47/100], Loss: 0.003287354603720208\n",
      "Epoch [48/100], Loss: 0.003201736780659606\n",
      "Epoch [49/100], Loss: 0.0029340013287340603\n",
      "Epoch [50/100], Loss: 0.00288205787849923\n",
      "Epoch [51/100], Loss: 0.0026706938383479913\n",
      "Epoch [52/100], Loss: 0.0024090340562785664\n",
      "Epoch [53/100], Loss: 0.0024591493397019804\n",
      "Epoch [54/100], Loss: 0.0022798555460758507\n",
      "Epoch [55/100], Loss: 0.0020343933642531435\n",
      "Epoch [56/100], Loss: 0.0019709988636896015\n",
      "Epoch [57/100], Loss: 0.0019398888002615422\n",
      "Epoch [58/100], Loss: 0.0018648626236245037\n",
      "Epoch [59/100], Loss: 0.0017207493272144347\n",
      "Epoch [60/100], Loss: 0.0015944944372555862\n",
      "Epoch [61/100], Loss: 0.0015605552242292711\n",
      "Epoch [62/100], Loss: 0.0013979986418659488\n",
      "Epoch [63/100], Loss: 0.0013847556873224675\n",
      "Epoch [64/100], Loss: 0.0012688279574892174\n",
      "Epoch [65/100], Loss: 0.0012523426782960693\n",
      "Epoch [66/100], Loss: 0.0012070316181052477\n",
      "Epoch [67/100], Loss: 0.0010721061972435563\n",
      "Epoch [68/100], Loss: 0.001089740153014039\n",
      "Epoch [69/100], Loss: 0.0009733931118777642\n",
      "Epoch [70/100], Loss: 0.0009469743181640903\n",
      "Epoch [71/100], Loss: 0.0009318705134016152\n",
      "Epoch [72/100], Loss: 0.0009026413725223392\n",
      "Epoch [73/100], Loss: 0.000822954021859914\n",
      "Epoch [74/100], Loss: 0.0007764664695908626\n",
      "Epoch [75/100], Loss: 0.0007697765079016487\n",
      "Epoch [76/100], Loss: 0.0007048482180107385\n",
      "Epoch [77/100], Loss: 0.0006913300985858465\n",
      "Epoch [78/100], Loss: 0.0006796878401655704\n",
      "Epoch [79/100], Loss: 0.0006706819291381786\n",
      "Epoch [80/100], Loss: 0.0006094647761589537\n",
      "Epoch [81/100], Loss: 0.0006002021396610265\n",
      "Epoch [82/100], Loss: 0.000534462104163443\n",
      "Epoch [83/100], Loss: 0.0005079425634661068\n",
      "Epoch [84/100], Loss: 0.0004899075953289867\n",
      "Epoch [85/100], Loss: 0.0004454478597229657\n",
      "Epoch [86/100], Loss: 0.000492308222843955\n",
      "Epoch [87/100], Loss: 0.00042828959800923864\n",
      "Epoch [88/100], Loss: 0.0004182880651205778\n",
      "Epoch [89/100], Loss: 0.0003831433657129916\n",
      "Epoch [90/100], Loss: 0.0003693583949158589\n",
      "Epoch [91/100], Loss: 0.00035461276595015077\n",
      "Epoch [92/100], Loss: 0.00033716278237989173\n",
      "Epoch [93/100], Loss: 0.00031813284537444514\n",
      "Epoch [94/100], Loss: 0.00030854989415577923\n",
      "Epoch [95/100], Loss: 0.00029211072348213444\n",
      "Epoch [96/100], Loss: 0.00028791844631390024\n",
      "Epoch [97/100], Loss: 0.00027666431027076517\n",
      "Epoch [98/100], Loss: 0.00026561185106402266\n",
      "Epoch [99/100], Loss: 0.0002559840947894069\n",
      "Epoch [100/100], Loss: 0.00024058009614236653\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = ENIGMABOT()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 100\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for i in range(len(data)):\n",
    "        sequence = data.loc[i, 'sequence']\n",
    "        target = data.loc[i, 'target']\n",
    "\n",
    "        # Featurize the input sequence\n",
    "        input_tensor = featurize(sequence)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(input_tensor)\n",
    "        loss = criterion(output, torch.LongTensor([ord(target)]))\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for the epoch\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'enigmabot_model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
